# -*- coding: utf-8 -*-
"""BCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1STmBGy0F7A7-VbswbivMV16uUhifLTvL
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

df=pd.read_csv('data.csv')
df=df.drop(columns=['id','Unnamed: 32'])
df['average_worst_factors']=round((df['radius_worst']+df['texture_worst']+df['perimeter_worst']+df['area_worst']+df['smoothness_worst']+df['compactness_worst']+df['concavity_worst']+df['concave points_worst']+df['symmetry_worst']+df['fractal_dimension_worst'])/10)
df['average_se_factors']=round((df['radius_se']+df['texture_se']+df['perimeter_se']+df['area_se']+df['smoothness_se']+df['compactness_se']+df['concavity_se']+df['concave points_se']+df['symmetry_se']+df['fractal_dimension_se'])/10)
df['average_mean_factors']=round((df['radius_mean']+df['texture_mean']+df['perimeter_mean']+df['area_mean']+df['smoothness_mean']+df['compactness_mean']+df['concavity_mean']+df['concave points_mean']+df['symmetry_mean']+df['fractal_dimension_mean'])/10)
df['conclusion']=df['diagnosis']
df=df.drop(columns=['diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean'])
df=df.drop(columns=['radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se'])
df=df.drop(columns=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst'])
df=df.dropna(how='any')
df

df['conclusion'].unique()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['conclusion']=le.fit_transform(df['conclusion'])
df

df['conclusion'].unique()

X=df.iloc[:,:-1].values
Y=df.iloc[:,-1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=15, activation='relu'))
ann.add(tf.keras.layers.Dense(units=15, activation='relu'))
ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
history = ann.fit(X_train, y_train, batch_size=15, epochs=150)
ann.save("BCR.h5")

plt.figure(0)
plt.plot(history.history['accuracy'], label='training accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.savefig('Accuracy.png')
plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.savefig('Loss.png')
print("Saved Model & Graph to disk")

model = tf.keras.models.load_model('BCR.h5')
print("Loaded model from disk")
test=[[100,150,200]]
print(ann.predict(test))

print(ann.predict([[37,2,26]]))

print(ann.predict([[10,25,26]]))

y_pred = ann.predict(X_test)
y_pred = (y_pred > 0.5)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(accuracy_score(y_test, y_pred)*100,"%")